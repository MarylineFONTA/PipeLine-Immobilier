name: Scrape & Clean (CI)

on:
  workflow_dispatch:        # lancement manuel
  push:
    branches: [ "main" ]    # √† chaque push sur main
  # schedule:               # d√©commente si tu veux l'ex√©cution auto quotidienne (UTC)
  #   - cron: "0 5 * * *"   # 05:00 UTC ~ 06/07:00 Europe/Paris

permissions:
  contents: write           # n√©cessaire pour commit/push avec GITHUB_TOKEN

concurrency:
  group: scrape-clean
  cancel-in-progress: true

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0     # permet le commit/push

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Run spider and cleaner
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data

          echo "‚ñ∂Ô∏è Running spider..."
          # adapte ces commandes √† ton repo
          python src/get_links_scrapy_nojs.py
          python src/spider.py

          # V√©rifier que le brut existe et n'est pas vide (si tu produis data/raw.csv)
          if [ -f data/raw.csv ]; then
            test -s data/raw.csv
            echo "raw.csv lignes:" $(wc -l < data/raw.csv) | tee -a $GITHUB_STEP_SUMMARY
          fi

          echo "üßπ Cleaning..."
          # si cleaner lit raw.csv et √©crit cleaned_data.csv
          python src/cleaner.py

          # V√©rifier la sortie
          test -s data/cleaned_data.csv
          echo "cleaned_data.csv lignes:" $(wc -l < data/cleaned_data.csv) | tee -a $GITHUB_STEP_SUMMARY

          # Validation rapide
          python - <<'PY'
          import pandas as pd, sys
          df = pd.read_csv("data/cleaned_data.csv", sep=";")
          req = ["price_eur","surface_m2","address"]
          miss = [c for c in req if c not in df.columns]
          assert not miss, f"Missing columns: {miss}"
          assert len(df) > 0, "Empty cleaned_data.csv"
          print(f"‚úÖ Validate OK: rows={len(df)}")
          PY

      - name: Commit & push CSV
        if: ${{ github.ref == 'refs/heads/main' }}
        run: |
          set -e
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/cleaned_data.csv
          if git diff --cached --quiet; then
            echo "‚ÑπÔ∏è Pas de changement √† committer." | tee -a $GITHUB_STEP_SUMMARY
          else
            # [skip ci] √©vite de relancer ce workflow par le commit de donn√©es
            git commit -m "CI: update data/cleaned_data.csv [skip ci]"
            git push
            echo "üì¶ CSV mis √† jour et pouss√©" | tee -a $GITHUB_STEP_SUMMARY
          fi

      - name: Upload CSV artifact (optional)
        uses: actions/upload-artifact@v4
        with:
          name: clean-csv
          path: data/cleaned_data.csv
          if-no-files-found: error
